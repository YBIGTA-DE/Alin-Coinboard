version: "3.8"

services:
  # Zookeeper service for kafka cluster
  zookeeper:
    image: confluentinc/cp-zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  # Kafka service
  # reachable on 9092 from the host and on 29092 from inside docker compose
  kafka:
    image: confluentinc/cp-kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    expose:
      - "29092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"

      KAFKA_MIN_INSYNC_REPLICAS: "1"

  # create a topic for kafka
  init-kafka:
    image: confluentinc/cp-kafka
    depends_on:
      - kafka
    entrypoint: ["/bin/sh", "-c"]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka:29092 --list
      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic dev.alin.binance.json --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic dev.alin.upbit.json --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic dev.alin.kimchi_premium.json --replication-factor 1 --partitions 1
      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka:29092 --list
      "
  binance-consumer:
    image: confluentinc/cp-kafka
    depends_on:
      - init-kafka
    entrypoint: ["/bin/sh", "-c"]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka:29092 --list
      kafka-console-consumer --bootstrap-server kafka:29092 --topic dev.alin.binance.json --from-beginning --property print.key=true --property key.separator=:
      "
  upbit-consumer:
    image: confluentinc/cp-kafka
    depends_on:
      - init-kafka
    entrypoint: ["/bin/sh", "-c"]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka:29092 --list
      kafka-console-consumer --bootstrap-server kafka:29092 --topic dev.alin.upbit.json --from-beginning --property print.key=true --property key.separator=:
      "
  kimchi-premium-consumer:
    image: confluentinc/cp-kafka
    depends_on:
      - init-kafka
    entrypoint: ["/bin/sh", "-c"]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka:29092 --list
      kafka-console-consumer --bootstrap-server kafka:29092 --topic dev.alin.kimchi_premium.json --from-beginning --property print.key=true --property key.separator=:
      "
  trading-volume-consumer:
    image: confluentinc/cp-kafka
    depends_on:
      - init-kafka
    entrypoint: ["/bin/sh", "-c"]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka:29092 --list
      kafka-console-consumer --bootstrap-server kafka:29092 --topic dev.alin.trading_volume.json --from-beginning --property print.key=true --property key.separator=:
      "
  kafka-streams-kimchipremium:
    build:
      context: ./streams
      dockerfile: Dockerfile-Kimchipremium
    container_name: kafka-streams-kimchipremium
    depends_on:
      - init-kafka

  kafka-streams-tradingvolume:
    build:
      context: ./streams
      dockerfile: Dockerfile-Tradingvolume
    container_name: kafka-streams-tradingvolume
    depends_on:
      - init-kafka

  s3-sink-connector:
    env_file:
      - ./s3-sink/.env
    build:
      context: ./s3-sink
      dockerfile: Dockerfile
    depends_on:
      - init-kafka
    entrypoint: ["/bin/sh", "-c"]
    command: |
      "
      aws configure set aws_access_key_id $${AWS_ACCESS_KEY_ID}
      aws configure set aws_secret_access_key $${AWS_SECRET_ACCESS_KEY}
      # blocks until kafka is reachable
      ./kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --list
      ./kafka/bin/connect-standalone.sh ./kafka/config/connect-standalone.properties ./kafka/config/s3-sink.properties
      "

  elasticsearch-sink-connector:
    build:
      context: ./elasticsearch-sink
      dockerfile: Dockerfile
    depends_on:
      - init-kafka
    entrypoint: ["/bin/sh", "-c"]
    command: |
      "
      # blocks until kafka is reachable
      ./kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --list

      ./kafka/bin/connect-standalone.sh ./kafka/config/connect-standalone.properties ./kafka/config/elasticsearch-sink.properties
      "

  # elasticsearch:
  #   image: docker.elastic.co/elasticsearch/elasticsearch:8.5.2
  #   container_name: elasticsearch
  #   environment:
  #     - discovery.type=single-node
  #   ports:
  #     - 9200:9200
  #     - 9300:9300
  #   volumes:
  #     - ./elasticsearch/data:/usr/share/elasticsearch/data
  #     - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml

  # kibana:
  #   image: docker.elastic.co/kibana/kibana:8.5.2
  #   container_name: kibana
  #   ports:
  #     - 5601:5601
  #   environment:
  #     - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
  #   depends_on:
  #     - elasticsearch

  # alin-coinboard-producer:
  #   build:
  #     context: ./producer
  #   depends_on:
  #     - init-kafka

  kafdrop:
    image: obsidiandynamics/kafdrop
    restart: "no"
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKER_CONNECT: "kafka:29092"
    depends_on:
      - kafka
